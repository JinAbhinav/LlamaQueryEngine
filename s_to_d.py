import subprocess
import pandas as pd

# Function to query Ollama model locally
def query_ollama(prompt, model="llama3.2"):
    try:
        # Run Ollama model using subprocess
        result = subprocess.run(
            ['ollama', 'run', model],   # Running the model locally
            input=prompt,              # Sending the prompt as input
            capture_output=True,       # Capture the output of the command
            text=True                  # Get the output as a string
        )
        
        # Check if the subprocess ran successfully
        if result.returncode != 0:
            return f"Error: {result.stderr}"
        
        # Extract the content from the output
        content = result.stdout.strip()
        
        # If no content is returned, handle accordingly
        if not content:
            return "No content generated by the model. Please check the model's status."
        
        return content

    except Exception as e:
        return f"Error: {str(e)}"


# Function to read multiple CSVs and merge them
def load_csvs(csv_files):
    dataframes = []
    for file in csv_files:
        try:
            df = pd.read_csv(file)
            dataframes.append(df)
        except Exception as e:
            return f"Error reading {file}: {str(e)}"
    
    # Merge all dataframes if there are multiple
    if len(dataframes) > 1:
        merged_df = pd.concat(dataframes, ignore_index=True)
    elif dataframes:
        merged_df = dataframes[0]
    else:
        return "No valid CSV files loaded."

    return merged_df

# Function to query the DataFrame using Ollama
def query_dataframe(query, dataframe):
    # Convert the DataFrame to a string for the LLM to process
    dataframe_text = dataframe.to_string(index=False)
    
    # Formulate the prompt
    prompt = f"""
    You are a helpful assistant. Below is the data from a company:

    {dataframe_text}

    Please answer the following query:
    {query}
    """
    
    # Query Ollama API and return the response
    return query_ollama(prompt)


# Example usage
csv_files = ['data1.csv', 'data2.csv']  # Replace with your actual CSV file paths
df = load_csvs(csv_files)

# Check if CSV loading was successful
if isinstance(df, pd.DataFrame):
    user_query = "find who this customer id 'DD37Cf93aecA6Dc' belongs to"
    response = query_dataframe(user_query, df)
    print(response)
else:
    print(df)  # Error message if CSV loading failed
